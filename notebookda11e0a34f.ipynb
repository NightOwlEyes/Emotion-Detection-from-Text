{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12005954,"sourceType":"datasetVersion","datasetId":7552835}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall fastai -y","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-05-31T15:36:55.184688Z","iopub.execute_input":"2025-05-31T15:36:55.184918Z","iopub.status.idle":"2025-05-31T15:36:57.942548Z","shell.execute_reply.started":"2025-05-31T15:36:55.184889Z","shell.execute_reply":"2025-05-31T15:36:57.941757Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: fastai 2.7.19\nUninstalling fastai-2.7.19:\n  Successfully uninstalled fastai-2.7.19\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install protobuf==3.20.*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:37:26.225810Z","iopub.execute_input":"2025-05-31T15:37:26.226089Z","iopub.status.idle":"2025-05-31T15:37:29.312840Z","shell.execute_reply.started":"2025-05-31T15:37:26.226050Z","shell.execute_reply":"2025-05-31T15:37:29.312131Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.11/dist-packages (3.20.3)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install \"torch>=1.7.0\"\n!pip install \"transformers>=4.5.0\"\n!pip install \"pandas>=1.1.0\"\n!pip install \"numpy>=1.19.0\"\n!pip install \"scikit-learn==1.4.2\"\n!pip install \"matplotlib>=3.3.0\"\n!pip install \"seaborn>=0.11.0\"\n!pip install \"tqdm>=4.50.0\"\n!pip install \"imbalanced-learn==0.12.0\"\n!pip install \"emoji>=2.14.1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:42:21.212466Z","iopub.execute_input":"2025-05-31T15:42:21.213283Z","iopub.status.idle":"2025-05-31T15:42:51.054725Z","shell.execute_reply.started":"2025-05-31T15:42:21.213248Z","shell.execute_reply":"2025-05-31T15:42:51.053824Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0) (3.0.2)\nRequirement already satisfied: transformers>=4.5.0 in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.5.0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.5.0) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.5.0) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.5.0) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.5.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.5.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.5.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.5.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.5.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.5.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.5.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.5.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.5.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.5.0) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers>=4.5.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers>=4.5.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers>=4.5.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers>=4.5.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers>=4.5.0) (2024.2.0)\nRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.1.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.1.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.1.0) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.0) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.1.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas>=1.1.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas>=1.1.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas>=1.1.0) (2024.2.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0) (2024.2.0)\nRequirement already satisfied: scikit-learn==1.4.2 in /usr/local/lib/python3.11/dist-packages (1.4.2)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=3.3.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=3.3.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=3.3.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=3.3.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=3.3.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=3.3.0) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib>=3.3.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib>=3.3.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib>=3.3.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib>=3.3.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib>=3.3.0) (2024.2.0)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from seaborn>=0.11.0) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn>=0.11.0) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from seaborn>=0.11.0) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn>=0.11.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn>=0.11.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn>=0.11.0) (2024.2.0)\nRequirement already satisfied: tqdm>=4.50.0 in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: imbalanced-learn==0.12.0 in /usr/local/lib/python3.11/dist-packages (0.12.0)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.12.0) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.12.0) (1.15.2)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.12.0) (1.4.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.12.0) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.12.0) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.12.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.12.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.12.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.12.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.12.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.12.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.12.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.12.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->imbalanced-learn==0.12.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->imbalanced-learn==0.12.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->imbalanced-learn==0.12.0) (2024.2.0)\nRequirement already satisfied: emoji>=2.14.1 in /usr/local/lib/python3.11/dist-packages (2.14.1)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nprint(torch.version.cuda)  # CUDA version PyTorch đang dùng\nprint(torch.backends.cudnn.version())  # cuDNN version\nprint(torch.cuda.is_available())  # Kiểm tra đã nhận GPU chưa\nprint(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:42:56.914111Z","iopub.execute_input":"2025-05-31T15:42:56.914666Z","iopub.status.idle":"2025-05-31T15:43:00.351718Z","shell.execute_reply.started":"2025-05-31T15:42:56.914633Z","shell.execute_reply":"2025-05-31T15:43:00.350996Z"}},"outputs":[{"name":"stdout","text":"12.4\n90100\nTrue\nTesla T4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#Xác định đường dẫn chứa dataset\nimport os\n\nfor root, dirs, files in os.walk('/kaggle/input'):\n    print(f'📂 {root}')\n    for file in files:\n        print(f'  └── {file}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:49:49.257216Z","iopub.execute_input":"2025-05-31T15:49:49.257811Z","iopub.status.idle":"2025-05-31T15:49:49.272035Z","shell.execute_reply.started":"2025-05-31T15:49:49.257785Z","shell.execute_reply":"2025-05-31T15:49:49.271490Z"}},"outputs":[{"name":"stdout","text":"📂 /kaggle/input\n📂 /kaggle/input/uit-vsmec\n  └── VnEmoLex.csv\n  └── valid.csv\n  └── train.csv\n  └── test.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Cell: Ghi file config.py để import ở các cell sau\nwith open(\"config.py\", \"w\", encoding=\"utf-8\") as f:\n    f.write('''# Cấu hình tham số cho mô hình nhận dạng cảm xúc văn bản\n\n# Cấu hình dữ liệu\nDATA_CONFIG = {\n    'train_path': '/kaggle/input/uit-vsmec/train.csv',\n    'valid_path': '/kaggle/input/uit-vsmec/valid.csv',\n    'test_path': '/kaggle/input/uit-vsmec/test.csv',\n    'vnemolex_path': '/kaggle/input/uit-vsmec/VnEmoLex.csv',\n    'max_len': 128,  # Độ dài tối đa của văn bản\n}\n\n# Cấu hình huấn luyện\nTRAINING_CONFIG = {\n    'batch_size': 32,\n    'epochs': 20,\n    'learning_rate': 2e-5,\n    'warmup_steps': 0,\n    'weight_decay': 0.01,\n    'dropout_rate': 0.3,\n    'early_stopping_patience': 3,  # Số epoch chờ đợi trước khi dừng sớm\n}\n\n# Cấu hình mô hình\nMODEL_CONFIG = {\n    'bert_model_name': 'uitnlp/CafeBERT',\n    'hidden_size': 512,  # Kích thước lớp ẩn\n    'num_classes': 6,  # Số lượng lớp cảm xúc (đã loại bỏ nhãn Other)\n}\n\n# Cấu hình đường dẫn\nPATH_CONFIG = {\n    'model_dir': 'models',\n    'best_model_path': 'models/best_model.pt',\n    'logs_dir': 'logs',\n    'results_dir': 'results',\n}\n\n# Ánh xạ nhãn cảm xúc\nEMOTION_MAPPING = {\n    'Anger': 0,\n    'Disgust': 1,\n    'Fear': 2,\n    'Enjoyment': 3,\n    'Sadness': 4,\n    'Surprise': 5\n}\n\n# Ánh xạ ngược lại từ số sang nhãn cảm xúc\nREVERSE_EMOTION_MAPPING = {v: k for k, v in EMOTION_MAPPING.items()}\n\n# Danh sách cảm xúc trong từ điển VnEmoLex\nVNEMOLEX_EMOTIONS = ['Anger', 'Disgust', 'Fear', 'Enjoyment', 'Sadness', 'Surprise']\n''')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:47:42.511153Z","iopub.execute_input":"2025-05-31T15:47:42.511413Z","iopub.status.idle":"2025-05-31T15:47:42.516249Z","shell.execute_reply.started":"2025-05-31T15:47:42.511394Z","shell.execute_reply":"2025-05-31T15:47:42.515699Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nimport emoji\nimport json\nimport time\nimport argparse\nfrom tqdm import tqdm\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\n\nimport sys\nif 'config' in sys.modules:\n    del sys.modules['config']\nfrom config import DATA_CONFIG, TRAINING_CONFIG, MODEL_CONFIG, PATH_CONFIG, EMOTION_MAPPING, REVERSE_EMOTION_MAPPING, VNEMOLEX_EMOTIONS\n\n# Tạo thư mục để lưu kết quả\nos.makedirs(PATH_CONFIG['results_dir'], exist_ok=True)\nos.makedirs(PATH_CONFIG['model_dir'], exist_ok=True)\nos.makedirs(PATH_CONFIG['logs_dir'], exist_ok=True)\n\n# Cấu hình thiết bị\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Sử dụng thiết bị: {device}\")\n\n# Hàm tiền xử lý văn bản\ndef preprocess_text(text):\n    text = text.strip().lower()                      # Chuyển về chữ thường\n    text = re.sub(r'\\s+', ' ', text)                 # Xóa khoảng trắng thừa\n    text = re.sub(r'\\d+', '', text)                  # Loại bỏ số\n    # Giữ lại emoji\n    emojis = ''.join(c for c in text if c in emoji.EMOJI_DATA)\n    # Loại ký tự đặc biệt, giữ lại chữ cái, khoảng trắng, dấu câu nhẹ\n    text = re.sub(r'[^\\w\\s\\.,!?]', '', text)\n    # Ghép lại với emoji nếu cần\n    return text.strip() + ' ' + emojis if emojis else text.strip()\n\n# Lưu thông tin tiền xử lý\ndef save_preprocessing_info():\n    with open(os.path.join(PATH_CONFIG['logs_dir'], 'preprocessing_info.txt'), 'w', encoding='utf-8') as f:\n        f.write(\"Quy trình tiền xử lý văn bản:\\n\")\n        f.write(\"1. Chuẩn hóa văn bản tiếng Việt sử dụng underthesea\\n\")\n        f.write(\"2. Chuyển về chữ thường\\n\")\n        f.write(\"3. Xóa khoảng trắng thừa\\n\")\n        f.write(\"4. Giữ nguyên emoji và ký tự đặc biệt\\n\")\n\n# Đọc dữ liệu\ndef load_data():\n    train_df = pd.read_csv(DATA_CONFIG['train_path'])\n    valid_df = pd.read_csv(DATA_CONFIG['valid_path'])\n    test_df = pd.read_csv(DATA_CONFIG['test_path'])\n    \n    # Xóa hàng có giá trị NaN\n    train_df = train_df.dropna()\n    valid_df = valid_df.dropna()\n    test_df = test_df.dropna()\n    \n    # Loại bỏ các mẫu có nhãn 'Other'\n    print(f\"Số lượng mẫu trong tập huấn luyện trước khi loại bỏ nhãn 'Other': {len(train_df)}\")\n    print(f\"Số lượng mẫu trong tập kiểm định trước khi loại bỏ nhãn 'Other': {len(valid_df)}\")\n    print(f\"Số lượng mẫu trong tập kiểm tra trước khi loại bỏ nhãn 'Other': {len(test_df)}\")\n    \n    train_df = train_df[train_df['Emotion'] != 'Other']\n    valid_df = valid_df[valid_df['Emotion'] != 'Other']\n    test_df = test_df[test_df['Emotion'] != 'Other']\n    \n    print(f\"Số lượng mẫu trong tập huấn luyện sau khi loại bỏ nhãn 'Other': {len(train_df)}\")\n    print(f\"Số lượng mẫu trong tập kiểm định sau khi loại bỏ nhãn 'Other': {len(valid_df)}\")\n    print(f\"Số lượng mẫu trong tập kiểm tra sau khi loại bỏ nhãn 'Other': {len(test_df)}\")\n    \n    # Tiền xử lý văn bản\n    train_df['Sentence'] = train_df['Sentence'].apply(preprocess_text)\n    valid_df['Sentence'] = valid_df['Sentence'].apply(preprocess_text)\n    test_df['Sentence'] = test_df['Sentence'].apply(preprocess_text)\n    \n    # Lưu dữ liệu đã tiền xử lý\n    train_df.to_csv(os.path.join(PATH_CONFIG['logs_dir'], 'preprocessed_train.csv'), index=False)\n    valid_df.to_csv(os.path.join(PATH_CONFIG['logs_dir'], 'preprocessed_valid.csv'), index=False)\n    test_df.to_csv(os.path.join(PATH_CONFIG['logs_dir'], 'preprocessed_test.csv'), index=False)\n    \n    # Phân tích phân phối nhãn\n    analyze_data_distribution(train_df, valid_df, test_df)\n    \n    return train_df, valid_df, test_df\n\n# Phân tích phân phối dữ liệu\ndef analyze_data_distribution(train_df, valid_df, test_df):\n    # Đếm số lượng mẫu cho mỗi cảm xúc\n    train_counts = train_df['Emotion'].value_counts()\n    valid_counts = valid_df['Emotion'].value_counts()\n    test_counts = test_df['Emotion'].value_counts()\n    \n    # Lưu thông tin phân phối\n    with open(os.path.join(PATH_CONFIG['logs_dir'], 'data_distribution.txt'), 'w', encoding='utf-8') as f:\n        f.write(\"Phân phối dữ liệu:\\n\")\n        f.write(f\"Tổng số mẫu huấn luyện: {len(train_df)}\\n\")\n        f.write(f\"Tổng số mẫu kiểm định: {len(valid_df)}\\n\")\n        f.write(f\"Tổng số mẫu kiểm tra: {len(test_df)}\\n\\n\")\n        \n        f.write(\"Phân phối nhãn trong tập huấn luyện:\\n\")\n        for emotion, count in train_counts.items():\n            f.write(f\"{emotion}: {count} ({count/len(train_df)*100:.2f}%)\\n\")\n        \n        f.write(\"\\nPhân phối nhãn trong tập kiểm định:\\n\")\n        for emotion, count in valid_counts.items():\n            f.write(f\"{emotion}: {count} ({count/len(valid_df)*100:.2f}%)\\n\")\n        \n        f.write(\"\\nPhân phối nhãn trong tập kiểm tra:\\n\")\n        for emotion, count in test_counts.items():\n            f.write(f\"{emotion}: {count} ({count/len(test_df)*100:.2f}%)\\n\")\n    \n    # Vẽ biểu đồ phân phối\n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 3, 1)\n    train_counts.plot(kind='bar', color='blue')\n    plt.title('Phân phối nhãn - Tập huấn luyện')\n    plt.ylabel('Số lượng mẫu')\n    plt.xticks(rotation=45)\n    \n    plt.subplot(1, 3, 2)\n    valid_counts.plot(kind='bar', color='green')\n    plt.title('Phân phối nhãn - Tập kiểm định')\n    plt.ylabel('Số lượng mẫu')\n    plt.xticks(rotation=45)\n    \n    plt.subplot(1, 3, 3)\n    test_counts.plot(kind='bar', color='red')\n    plt.title('Phân phối nhãn - Tập kiểm tra')\n    plt.ylabel('Số lượng mẫu')\n    plt.xticks(rotation=45)\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(PATH_CONFIG['results_dir'], 'data_distribution.png'))\n    plt.close()\n    \n    return train_counts\n\n# Đọc từ điển cảm xúc VnEmoLex\ndef load_vnemolex():\n    vnemolex_df = pd.read_csv(DATA_CONFIG['vnemolex_path'])\n    \n    # Tạo từ điển cảm xúc\n    emotion_dict = {}\n    for _, row in vnemolex_df.iterrows():\n        word = row['Vietnamese']\n        emotions = {}\n        for emotion in VNEMOLEX_EMOTIONS:\n            if emotion in row and row[emotion] == 1:\n                emotions[emotion] = 1\n        if emotions:\n            emotion_dict[word] = emotions\n    \n    # Lưu thông tin từ điển\n    with open(os.path.join(PATH_CONFIG['logs_dir'], 'vnemolex_info.txt'), 'w', encoding='utf-8') as f:\n        f.write(f\"Tổng số từ trong từ điển VnEmoLex: {len(emotion_dict)}\\n\")\n        emotion_counts = {emotion: 0 for emotion in VNEMOLEX_EMOTIONS}\n        for word, emotions in emotion_dict.items():\n            for emotion in emotions:\n                emotion_counts[emotion] += 1\n        f.write(\"Số lượng từ cho mỗi cảm xúc:\\n\")\n        for emotion, count in emotion_counts.items():\n            f.write(f\"{emotion}: {count}\\n\")\n    \n    return emotion_dict\n\n# Tạo đặc trưng từ từ điển cảm xúc\ndef extract_lexicon_features(text, emotion_dict):\n    words = text.split()\n    features = {emotion: 0 for emotion in VNEMOLEX_EMOTIONS}\n    \n    for word in words:\n        if word in emotion_dict:\n            for emotion, value in emotion_dict[word].items():\n                features[emotion] += value\n    \n    # Chuẩn hóa đặc trưng\n    total = sum(features.values())\n    if total > 0:\n        for emotion in features:\n            features[emotion] /= total\n    \n    return list(features.values())\n\n# Tạo dataset PyTorch\nclass EmotionDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len, emotion_dict):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.emotion_dict = emotion_dict\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        text = self.data.iloc[index]['Sentence']\n        emotion = self.data.iloc[index]['Emotion']\n        \n        # Tokenize văn bản\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        # Trích xuất đặc trưng từ từ điển cảm xúc\n        lexicon_features = extract_lexicon_features(text, self.emotion_dict)\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'lexicon_features': torch.tensor(lexicon_features, dtype=torch.float),\n            'label': torch.tensor(EMOTION_MAPPING[emotion], dtype=torch.long)\n        }\n\n# Mô hình phân loại cảm xúc\nclass EmotionClassifier(nn.Module):\n    def __init__(self, bert_model, num_classes=MODEL_CONFIG['num_classes']):\n        super(EmotionClassifier, self).__init__()\n        self.bert = bert_model\n        self.dropout = nn.Dropout(TRAINING_CONFIG['dropout_rate'])\n        \n        # Kích thước đầu ra của mô hình BERT\n        self.bert_output_dim = self.bert.config.hidden_size\n        \n        # Số đặc trưng từ từ điển cảm xúc\n        self.lexicon_features_dim = len(VNEMOLEX_EMOTIONS)\n        \n        # Lớp kết hợp đặc trưng BERT và đặc trưng từ điển\n        self.feature_combiner = nn.Linear(self.bert_output_dim + self.lexicon_features_dim, MODEL_CONFIG['hidden_size'])\n        \n        # Lớp phân loại\n        self.classifier = nn.Linear(MODEL_CONFIG['hidden_size'], num_classes)\n        \n        # Hàm kích hoạt\n        self.relu = nn.ReLU()\n    \n    def forward(self, input_ids, attention_mask, lexicon_features):\n        # Đầu ra từ mô hình BERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        \n        # Kết hợp đặc trưng BERT và đặc trưng từ điển\n        combined_features = torch.cat((pooled_output, lexicon_features), dim=1)\n        combined_features = self.feature_combiner(combined_features)\n        combined_features = self.relu(combined_features)\n        combined_features = self.dropout(combined_features)\n        \n        # Phân loại\n        logits = self.classifier(combined_features)\n        \n        return logits\n\n# Tính trọng số cho từng lớp dựa trên tần suất xuất hiện\ndef calculate_class_weights(train_df):\n    class_counts = train_df['Emotion'].value_counts().to_dict()\n    total_samples = len(train_df)\n    \n    # Tính trọng số nghịch đảo tần suất lớp\n    class_weights = {emotion: total_samples / (len(class_counts) * count) \n                    for emotion, count in class_counts.items()}\n    \n    # Chuyển đổi thành tensor\n    weights = torch.FloatTensor([class_weights[emotion] for emotion in REVERSE_EMOTION_MAPPING.values()])\n    \n    # Lưu thông tin trọng số\n    with open(os.path.join(PATH_CONFIG['logs_dir'], 'class_weights.txt'), 'w', encoding='utf-8') as f:\n        f.write(\"Trọng số cho từng lớp cảm xúc:\\n\")\n        for emotion, weight in class_weights.items():\n            f.write(f\"{emotion}: {weight:.4f}\\n\")\n    \n    return weights\n\n# Tạo sampler cho dữ liệu mất cân bằng\ndef create_weighted_sampler(train_df):\n    # Lấy nhãn\n    train_labels = [EMOTION_MAPPING[emotion] for emotion in train_df['Emotion']]\n    \n    # Đếm số lượng mẫu cho mỗi lớp\n    class_counts = Counter(train_labels)\n    \n    # Tính trọng số cho từng mẫu\n    weights = [1.0 / class_counts[label] for label in train_labels]\n    \n    # Tạo sampler\n    sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n    \n    return sampler\n\n# Áp dụng oversampling cho dữ liệu mất cân bằng\ndef apply_oversampling(train_df):\n    # Tách features và labels\n    X = train_df.index.values.reshape(-1, 1)  # Sử dụng chỉ số làm đặc trưng\n    y = train_df['Emotion'].values\n    \n    # Áp dụng RandomOverSampler\n    ros = RandomOverSampler(random_state=42)\n    X_resampled, y_resampled = ros.fit_resample(X, y)\n    \n    # Tạo DataFrame mới với dữ liệu đã được oversampling\n    resampled_indices = X_resampled.flatten()\n    oversampled_df = train_df.iloc[resampled_indices].copy()\n    oversampled_df['Emotion'] = y_resampled\n    \n    # Lưu thông tin oversampling\n    with open(os.path.join(PATH_CONFIG['logs_dir'], 'oversampling_info.txt'), 'w', encoding='utf-8') as f:\n        f.write(\"Thông tin oversampling:\\n\")\n        f.write(f\"Số lượng mẫu trước khi oversampling: {len(train_df)}\\n\")\n        f.write(f\"Số lượng mẫu sau khi oversampling: {len(oversampled_df)}\\n\\n\")\n        \n        original_counts = train_df['Emotion'].value_counts()\n        resampled_counts = oversampled_df['Emotion'].value_counts()\n        \n        f.write(\"Phân phối nhãn trước khi oversampling:\\n\")\n        for emotion, count in original_counts.items():\n            f.write(f\"{emotion}: {count} ({count/len(train_df)*100:.2f}%)\\n\")\n        \n        f.write(\"\\nPhân phối nhãn sau khi oversampling:\\n\")\n        for emotion, count in resampled_counts.items():\n            f.write(f\"{emotion}: {count} ({count/len(oversampled_df)*100:.2f}%)\\n\")\n    \n    # Vẽ biểu đồ so sánh phân phối trước và sau khi oversampling\n    plt.figure(figsize=(12, 6))\n    \n    plt.subplot(1, 2, 1)\n    original_counts.plot(kind='bar', color='blue')\n    plt.title('Phân phối nhãn trước khi oversampling')\n    plt.ylabel('Số lượng mẫu')\n    plt.xticks(rotation=45)\n    \n    plt.subplot(1, 2, 2)\n    resampled_counts.plot(kind='bar', color='green')\n    plt.title('Phân phối nhãn sau khi oversampling')\n    plt.ylabel('Số lượng mẫu')\n    plt.xticks(rotation=45)\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(PATH_CONFIG['results_dir'], 'oversampling_distribution.png'))\n    plt.close()\n    \n    return oversampled_df\n\n# Hàm huấn luyện mô hình\ndef train_model(model, train_dataloader, val_dataloader, optimizer, scheduler, device, epochs, class_weights=None):\n    # Hàm mất mát với trọng số lớp (nếu có)\n    if class_weights is not None:\n        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n        print(\"Sử dụng trọng số lớp cho hàm mất mát\")\n    else:\n        criterion = nn.CrossEntropyLoss()\n    \n    # Lưu lịch sử huấn luyện\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'val_macro_f1': [],\n        'val_weighted_f1': [],\n        'val_class_f1': []\n    }\n    \n    # Lưu mô hình tốt nhất\n    best_val_f1 = 0\n    patience_counter = 0\n    \n    # Bắt đầu huấn luyện\n    for epoch in range(epochs):\n        print(f'Epoch {epoch+1}/{epochs}')\n        print('-' * 10)\n        \n        # ===== Huấn luyện =====\n        model.train()\n        train_loss = 0\n        \n        progress_bar = tqdm(train_dataloader, desc=\"Training\")\n        for batch in progress_bar:\n            # Đưa dữ liệu lên thiết bị\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            lexicon_features = batch['lexicon_features'].to(device)\n            labels = batch['label'].to(device)\n            \n            # Xóa gradient\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(input_ids, attention_mask, lexicon_features)\n            \n            # Tính mất mát\n            loss = criterion(outputs, labels)\n            train_loss += loss.item()\n            \n            # Backward pass\n            loss.backward()\n            \n            # Cập nhật tham số\n            optimizer.step()\n            scheduler.step()\n            \n            # Cập nhật thanh tiến trình\n            progress_bar.set_postfix({'loss': loss.item()})\n        \n        # Tính mất mát trung bình trên tập huấn luyện\n        avg_train_loss = train_loss / len(train_dataloader)\n        history['train_loss'].append(avg_train_loss)\n        \n        # ===== Đánh giá =====\n        model.eval()\n        val_loss = 0\n        val_preds = []\n        val_labels = []\n        \n        with torch.no_grad():\n            progress_bar = tqdm(val_dataloader, desc=\"Validation\")\n            for batch in progress_bar:\n                # Đưa dữ liệu lên thiết bị\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                lexicon_features = batch['lexicon_features'].to(device)\n                labels = batch['label'].to(device)\n                \n                # Forward pass\n                outputs = model(input_ids, attention_mask, lexicon_features)\n                \n                # Tính mất mát\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                \n                # Lấy dự đoán\n                _, preds = torch.max(outputs, dim=1)\n                \n                # Lưu dự đoán và nhãn\n                val_preds.extend(preds.cpu().tolist())\n                val_labels.extend(labels.cpu().tolist())\n                \n                # Cập nhật thanh tiến trình\n                progress_bar.set_postfix({'loss': loss.item()})\n        \n        # Tính mất mát trung bình trên tập kiểm định\n        avg_val_loss = val_loss / len(val_dataloader)\n        history['val_loss'].append(avg_val_loss)\n        \n        # Tính các chỉ số đánh giá (loại bỏ Accuracy vì bộ dữ liệu mất cân bằng)\n        val_macro_f1 = f1_score(val_labels, val_preds, average='macro')\n        val_weighted_f1 = f1_score(val_labels, val_preds, average='weighted')\n        val_class_f1 = f1_score(val_labels, val_preds, average=None)\n        \n        history['val_macro_f1'].append(val_macro_f1)\n        history['val_weighted_f1'].append(val_weighted_f1)\n        history['val_class_f1'].append(val_class_f1.tolist())\n        \n        print(f'Train Loss: {avg_train_loss:.4f}')\n        print(f'Val Loss: {avg_val_loss:.4f}')\n        print(f'Val Macro F1: {val_macro_f1:.4f}')\n        print(f'Val Weighted F1: {val_weighted_f1:.4f}')\n        print('\\nF1-score cho từng lớp:')\n        class_names = [REVERSE_EMOTION_MAPPING[i] for i in range(len(REVERSE_EMOTION_MAPPING))]\n        for i, class_name in enumerate(class_names):\n            print(f'{class_name}: {val_class_f1[i]:.4f}')\n        \n        # Lưu mô hình tốt nhất dựa trên Macro F1\n        if val_macro_f1 > best_val_f1:\n            best_val_f1 = val_macro_f1\n            torch.save(model.state_dict(), os.path.join(PATH_CONFIG['model_dir'], 'best_model.pt'))\n            print(\"Đã lưu mô hình tốt nhất!\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        # Dừng sớm nếu không cải thiện sau một số epoch\n        if patience_counter >= TRAINING_CONFIG['early_stopping_patience']:\n            print(f\"Dừng sớm sau {epoch+1} epochs vì không cải thiện!\")\n            break\n    \n    # Vẽ biểu đồ lịch sử huấn luyện\n    plot_training_history(history)\n    \n    # Lưu lịch sử huấn luyện\n    with open(os.path.join(PATH_CONFIG['logs_dir'], 'training_history.json'), 'w') as f:\n        json.dump(history, f)\n    \n    return history\n\n# Vẽ biểu đồ lịch sử huấn luyện\ndef plot_training_history(history):\n    plt.figure(figsize=(15, 10))\n    \n    # Vẽ biểu đồ mất mát\n    plt.subplot(2, 2, 1)\n    plt.plot(history['train_loss'], label='Train Loss')\n    plt.plot(history['val_loss'], label='Val Loss')\n    plt.title('Mất mát qua các epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Vẽ biểu đồ F1-score cho từng lớp\n    plt.subplot(2, 2, 2)\n    class_names = [REVERSE_EMOTION_MAPPING[i] for i in range(len(REVERSE_EMOTION_MAPPING))]\n    for i, class_name in enumerate(class_names):\n        class_f1_values = [epoch_f1[i] for epoch_f1 in history['val_class_f1']]\n        plt.plot(class_f1_values, label=class_name)\n    plt.title('F1-score cho từng lớp qua các epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('F1-score')\n    plt.legend()\n    \n    # Vẽ biểu đồ F1-score\n    plt.subplot(2, 2, 3)\n    plt.plot(history['val_macro_f1'], label='Macro F1')\n    plt.plot(history['val_weighted_f1'], label='Weighted F1')\n    plt.title('F1-score qua các epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('F1-score')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(PATH_CONFIG['results_dir'], 'training_history.png'))\n    plt.close()\n\n# Đánh giá mô hình trên tập kiểm tra\ndef evaluate_model(model, test_dataloader, device):\n    # Chuyển mô hình sang chế độ đánh giá\n    model.eval()\n    \n    # Lưu dự đoán và nhãn\n    all_preds = []\n    all_labels = []\n    \n    # Không tính gradient\n    with torch.no_grad():\n        progress_bar = tqdm(test_dataloader, desc=\"Testing\")\n        for batch in progress_bar:\n            # Đưa dữ liệu lên thiết bị\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            lexicon_features = batch['lexicon_features'].to(device)\n            labels = batch['label'].to(device)\n            \n            # Forward pass\n            outputs = model(input_ids, attention_mask, lexicon_features)\n            \n            # Lấy dự đoán\n            _, preds = torch.max(outputs, dim=1)\n            \n            # Lưu dự đoán và nhãn\n            all_preds.extend(preds.cpu().tolist())\n            all_labels.extend(labels.cpu().tolist())\n    \n    # Tính các chỉ số đánh giá (loại bỏ Accuracy vì bộ dữ liệu mất cân bằng)\n    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n    weighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n    class_f1 = f1_score(all_labels, all_preds, average=None)\n    \n    # Tính ma trận nhầm lẫn\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    # Lưu kết quả đánh giá\n    with open(os.path.join(PATH_CONFIG['results_dir'], 'evaluation_results.txt'), 'w') as f:\n        f.write(f\"Macro F1-score: {macro_f1:.4f}\\n\")\n        f.write(f\"Weighted F1-score: {weighted_f1:.4f}\\n\\n\")\n        f.write(\"F1-score cho từng lớp:\\n\")\n        class_names = [REVERSE_EMOTION_MAPPING[i] for i in range(len(REVERSE_EMOTION_MAPPING))]\n        for i, class_name in enumerate(class_names):\n            f.write(f\"{class_name}: {class_f1[i]:.4f}\\n\")\n    \n    # Vẽ ma trận nhầm lẫn\n    plot_confusion_matrix(cm)\n    \n    return macro_f1, weighted_f1, class_f1, cm\n\n# Vẽ ma trận nhầm lẫn\ndef plot_confusion_matrix(cm):\n    # Danh sách nhãn cảm xúc\n    labels = list(EMOTION_MAPPING.keys())\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n    plt.title('Ma trận nhầm lẫn')\n    plt.xlabel('Dự đoán')\n    plt.ylabel('Thực tế')\n    plt.tight_layout()\n    plt.savefig(os.path.join(PATH_CONFIG['results_dir'], 'confusion_matrix.png'))\n    plt.close()\n\n# Hàm dự đoán cảm xúc cho văn bản mới\ndef predict_emotion(text, model, tokenizer, emotion_dict, device):\n    # Tiền xử lý văn bản sử dụng underthesea\n    text = preprocess_text(text)\n    \n    # Tokenize văn bản\n    encoding = tokenizer(\n        text,\n        add_special_tokens=True,\n        max_length=DATA_CONFIG['max_len'],\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    # Trích xuất đặc trưng từ từ điển cảm xúc\n    lexicon_features = extract_lexicon_features(text, emotion_dict)\n    \n    # Đưa dữ liệu lên thiết bị\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    lexicon_features = torch.tensor([lexicon_features], dtype=torch.float).to(device)\n    \n    # Dự đoán\n    model.eval()\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask, lexicon_features)\n        _, preds = torch.max(outputs, dim=1)\n    \n    return REVERSE_EMOTION_MAPPING[preds.item()]\n\n# Hàm chính\ndef main():\n    # Phân tích tham số dòng lệnh\n    parser = argparse.ArgumentParser(description='Huấn luyện mô hình nhận dạng cảm xúc văn bản')\n    parser.add_argument('--imbalance_method', type=str, default='weighted_sampler', \n                        choices=['none', 'class_weight', 'weighted_sampler', 'oversampling'],\n                        help='Phương pháp xử lý dữ liệu mất cân bằng')\n    args = parser.parse_args([])\n    \n    # Bắt đầu đo thời gian\n    start_time = time.time()\n    \n    # Lưu thông tin tiền xử lý\n    save_preprocessing_info()\n    \n    # Đọc dữ liệu\n    print(\"Đang đọc dữ liệu...\")\n    train_df, valid_df, test_df = load_data()\n    \n    # Xử lý dữ liệu mất cân bằng\n    class_weights = None\n    sampler = None\n    \n    if args.imbalance_method == 'class_weight':\n        print(\"Áp dụng trọng số lớp cho dữ liệu mất cân bằng...\")\n        class_weights = calculate_class_weights(train_df)\n    elif args.imbalance_method == 'weighted_sampler':\n        print(\"Áp dụng weighted sampler cho dữ liệu mất cân bằng...\")\n        sampler = create_weighted_sampler(train_df)\n    elif args.imbalance_method == 'oversampling':\n        print(\"Áp dụng oversampling cho dữ liệu mất cân bằng...\")\n        train_df = apply_oversampling(train_df)\n    else:\n        print(\"Không áp dụng phương pháp xử lý dữ liệu mất cân bằng\")\n    \n    # Đọc từ điển cảm xúc\n    print(\"Đang đọc từ điển cảm xúc...\")\n    emotion_dict = load_vnemolex()\n    \n    # Tải mô hình và tokenizer\n    print(\"Đang tải mô hình CafeBERT...\")\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_CONFIG['bert_model_name'])\n    bert_model = AutoModel.from_pretrained(MODEL_CONFIG['bert_model_name'])\n    \n    # Tạo dataset\n    print(\"Đang tạo dataset...\")\n    train_dataset = EmotionDataset(train_df, tokenizer, DATA_CONFIG['max_len'], emotion_dict)\n    valid_dataset = EmotionDataset(valid_df, tokenizer, DATA_CONFIG['max_len'], emotion_dict)\n    test_dataset = EmotionDataset(test_df, tokenizer, DATA_CONFIG['max_len'], emotion_dict)\n    \n    # Tạo dataloader\n    if args.imbalance_method == 'weighted_sampler' and sampler is not None:\n        train_dataloader = DataLoader(train_dataset, batch_size=TRAINING_CONFIG['batch_size'], sampler=sampler)\n        print(\"Sử dụng weighted sampler cho train dataloader\")\n    else:\n        train_dataloader = DataLoader(train_dataset, batch_size=TRAINING_CONFIG['batch_size'], shuffle=True)\n    \n    valid_dataloader = DataLoader(valid_dataset, batch_size=TRAINING_CONFIG['batch_size'])\n    test_dataloader = DataLoader(test_dataset, batch_size=TRAINING_CONFIG['batch_size'])\n    \n    # Tạo mô hình\n    print(\"Đang khởi tạo mô hình...\")\n    model = EmotionClassifier(bert_model)\n    model.to(device)\n    \n    # Tạo optimizer và scheduler\n    optimizer = optim.AdamW(model.parameters(), lr=TRAINING_CONFIG['learning_rate'], \n                           weight_decay=TRAINING_CONFIG['weight_decay'])\n    total_steps = len(train_dataloader) * TRAINING_CONFIG['epochs']\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=TRAINING_CONFIG['warmup_steps'],\n        num_training_steps=total_steps\n    )\n    \n    # Huấn luyện mô hình\n    print(\"Bắt đầu huấn luyện mô hình...\")\n    history = train_model(model, train_dataloader, valid_dataloader, optimizer, scheduler, \n                         device, TRAINING_CONFIG['epochs'], class_weights)\n    \n    # Tải mô hình tốt nhất\n    print(\"Đang tải mô hình tốt nhất...\")\n    model.load_state_dict(torch.load(os.path.join(PATH_CONFIG['model_dir'], 'best_model.pt')))\n    \n    # Đánh giá mô hình trên tập kiểm tra\n    print(\"Đang đánh giá mô hình...\")\n    macro_f1, weighted_f1, class_f1, cm = evaluate_model(model, test_dataloader, device)\n    \n    print(f\"Macro F1-score: {macro_f1:.4f}\")\n    print(f\"Weighted F1-score: {weighted_f1:.4f}\")\n    print(\"\\nF1-score cho từng lớp:\")\n    class_names = [REVERSE_EMOTION_MAPPING[i] for i in range(len(REVERSE_EMOTION_MAPPING))]\n    for i, class_name in enumerate(class_names):\n        print(f\"{class_name}: {class_f1[i]:.4f}\")\n    \n    # Kết thúc đo thời gian\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n    \n    print(f\"Thời gian thực thi: {elapsed_time:.2f} giây\")\n    \n    # Lưu thông tin thời gian\n    with open(os.path.join(PATH_CONFIG['logs_dir'], 'execution_time.txt'), 'w') as f:\n        f.write(f\"Thời gian thực thi: {elapsed_time:.2f} giây\\n\")\n        f.write(f\"Phương pháp xử lý dữ liệu mất cân bằng: {args.imbalance_method}\\n\")\n\n# Chạy chương trình\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T15:52:04.411590Z","iopub.execute_input":"2025-05-31T15:52:04.412322Z","iopub.status.idle":"2025-05-31T16:30:09.175485Z","shell.execute_reply.started":"2025-05-31T15:52:04.412296Z","shell.execute_reply":"2025-05-31T16:30:09.174946Z"}},"outputs":[{"name":"stdout","text":"Sử dụng thiết bị: cuda\nĐang đọc dữ liệu...\nSố lượng mẫu trong tập huấn luyện trước khi loại bỏ nhãn 'Other': 5548\nSố lượng mẫu trong tập kiểm định trước khi loại bỏ nhãn 'Other': 686\nSố lượng mẫu trong tập kiểm tra trước khi loại bỏ nhãn 'Other': 693\nSố lượng mẫu trong tập huấn luyện sau khi loại bỏ nhãn 'Other': 4527\nSố lượng mẫu trong tập kiểm định sau khi loại bỏ nhãn 'Other': 545\nSố lượng mẫu trong tập kiểm tra sau khi loại bỏ nhãn 'Other': 564\nÁp dụng weighted sampler cho dữ liệu mất cân bằng...\nĐang đọc từ điển cảm xúc...\nĐang tải mô hình CafeBERT...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/496 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48d2023a2f5b4af5897de6638866f4e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573296dd1c164a92acea13f8a6c4836e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f9f7cf147b416b9969a532b3a2de3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1e2c7a22f54456688562eb06a309ca5"}},"metadata":{}},{"name":"stderr","text":"2025-05-31 15:52:27.458350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748706747.699031      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748706747.768173      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08f739a54e564c1192b14f31d7e6ad22"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Đang tạo dataset...\nSử dụng weighted sampler cho train dataloader\nĐang khởi tạo mô hình...\nBắt đầu huấn luyện mô hình...\nEpoch 1/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 142/142 [04:56<00:00,  2.09s/it, loss=1.13] \nValidation: 100%|██████████| 18/18 [00:11<00:00,  1.62it/s, loss=0.589]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2879\nVal Loss: 0.9810\nVal Macro F1: 0.5840\nVal Weighted F1: 0.6488\n\nF1-score cho từng lớp:\nAnger: 0.3908\nDisgust: 0.6017\nFear: 0.5714\nEnjoyment: 0.7750\nSadness: 0.6197\nSurprise: 0.5455\nĐã lưu mô hình tốt nhất!\nEpoch 2/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 142/142 [05:05<00:00,  2.15s/it, loss=0.638]\nValidation: 100%|██████████| 18/18 [00:11<00:00,  1.62it/s, loss=0.114]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6896\nVal Loss: 0.9180\nVal Macro F1: 0.6295\nVal Weighted F1: 0.6847\n\nF1-score cho từng lớp:\nAnger: 0.4741\nDisgust: 0.5804\nFear: 0.5806\nEnjoyment: 0.8250\nSadness: 0.6705\nSurprise: 0.6462\nĐã lưu mô hình tốt nhất!\nEpoch 3/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 142/142 [05:05<00:00,  2.15s/it, loss=0.355]\nValidation: 100%|██████████| 18/18 [00:11<00:00,  1.62it/s, loss=0.118]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4890\nVal Loss: 0.9527\nVal Macro F1: 0.6354\nVal Weighted F1: 0.6828\n\nF1-score cho từng lớp:\nAnger: 0.4874\nDisgust: 0.6133\nFear: 0.6269\nEnjoyment: 0.7893\nSadness: 0.6826\nSurprise: 0.6129\nĐã lưu mô hình tốt nhất!\nEpoch 4/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 142/142 [05:05<00:00,  2.15s/it, loss=0.283] \nValidation: 100%|██████████| 18/18 [00:11<00:00,  1.62it/s, loss=0.088]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3939\nVal Loss: 0.9293\nVal Macro F1: 0.6545\nVal Weighted F1: 0.6943\n\nF1-score cho từng lớp:\nAnger: 0.5185\nDisgust: 0.6182\nFear: 0.6780\nEnjoyment: 0.8020\nSadness: 0.6704\nSurprise: 0.6400\nĐã lưu mô hình tốt nhất!\nEpoch 5/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 142/142 [05:05<00:00,  2.15s/it, loss=0.243] \nValidation: 100%|██████████| 18/18 [00:11<00:00,  1.62it/s, loss=0.104]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2857\nVal Loss: 0.8892\nVal Macro F1: 0.6446\nVal Weighted F1: 0.7114\n\nF1-score cho từng lớp:\nAnger: 0.3836\nDisgust: 0.6817\nFear: 0.6780\nEnjoyment: 0.8317\nSadness: 0.6982\nSurprise: 0.5946\nEpoch 6/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 142/142 [05:05<00:00,  2.15s/it, loss=0.396] \nValidation: 100%|██████████| 18/18 [00:11<00:00,  1.63it/s, loss=0.0269]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2173\nVal Loss: 0.9901\nVal Macro F1: 0.6466\nVal Weighted F1: 0.7141\n\nF1-score cho từng lớp:\nAnger: 0.5094\nDisgust: 0.6565\nFear: 0.6032\nEnjoyment: 0.8518\nSadness: 0.6585\nSurprise: 0.6000\nEpoch 7/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 142/142 [05:04<00:00,  2.15s/it, loss=0.0532]\nValidation: 100%|██████████| 18/18 [00:11<00:00,  1.62it/s, loss=0.0677]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1653\nVal Loss: 1.0665\nVal Macro F1: 0.6448\nVal Weighted F1: 0.7113\n\nF1-score cho từng lớp:\nAnger: 0.4634\nDisgust: 0.6882\nFear: 0.6296\nEnjoyment: 0.8269\nSadness: 0.6739\nSurprise: 0.5867\nDừng sớm sau 7 epochs vì không cải thiện!\nĐang tải mô hình tốt nhất...\nĐang đánh giá mô hình...\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 18/18 [00:11<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Macro F1-score: 0.6828\nWeighted F1-score: 0.7191\n\nF1-score cho từng lớp:\nAnger: 0.4416\nDisgust: 0.6621\nFear: 0.7742\nEnjoyment: 0.7898\nSadness: 0.7542\nSurprise: 0.6750\nThời gian thực thi: 2275.24 giây\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer\nimport pandas as pd\nimport re\nimport argparse\nimport emoji\n# Cấu hình thiết bị\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Cấu hình tham số\nMAX_LEN = 128\n\n# Hàm tiền xử lý văn bản\ndef preprocess_text(text):\n    text = text.strip().lower()                      # Chuyển về chữ thường\n    text = re.sub(r'\\s+', ' ', text)                 # Xóa khoảng trắng thừa\n    text = re.sub(r'\\d+', '', text)                  # Loại bỏ số\n    # Giữ lại emoji\n    emojis = ''.join(c for c in text if c in emoji.EMOJI_DATA)\n    # Loại ký tự đặc biệt, giữ lại chữ cái, khoảng trắng, dấu câu nhẹ\n    text = re.sub(r'[^\\w\\s\\.,!?]', '', text)\n    # Ghép lại với emoji nếu cần\n    return text.strip() + ' ' + emojis if emojis else text.strip()\n\n# Đọc từ điển cảm xúc VnEmoLex\ndef load_vnemolex():\n    vnemolex_df = pd.read_csv('/kaggle/input/uit-vsmec/VnEmoLex.csv')\n    \n    # Tạo từ điển cảm xúc\n    emotion_dict = {}\n    for _, row in vnemolex_df.iterrows():\n        word = row['Vietnamese']\n        emotions = {}\n        for emotion in ['Anger', 'Disgust', 'Fear', 'Enjoyment', 'Sadness', 'Surprise']:\n            if emotion in row and row[emotion] == 1:\n                emotions[emotion] = 1\n        if emotions:\n            emotion_dict[word] = emotions\n    \n    return emotion_dict\n\n# Tạo đặc trưng từ từ điển cảm xúc\ndef extract_lexicon_features(text, emotion_dict):\n    words = text.split()\n    features = {emotion: 0 for emotion in ['Anger', 'Disgust', 'Fear', 'Enjoyment', 'Sadness', 'Surprise']}\n    \n    for word in words:\n        if word in emotion_dict:\n            for emotion, value in emotion_dict[word].items():\n                features[emotion] += value\n    \n    # Chuẩn hóa đặc trưng\n    total = sum(features.values())\n    if total > 0:\n        for emotion in features:\n            features[emotion] /= total\n    \n    return list(features.values())\n\n# Mô hình phân loại cảm xúc\nclass EmotionClassifier(nn.Module):\n    def __init__(self, bert_model, num_classes=6):\n        super(EmotionClassifier, self).__init__()\n        self.bert = bert_model\n        self.dropout = nn.Dropout(0.3)\n        \n        # Kích thước đầu ra của mô hình BERT\n        self.bert_output_dim = self.bert.config.hidden_size\n        \n        # Số đặc trưng từ từ điển cảm xúc\n        self.lexicon_features_dim = 6\n        \n        # Lớp kết hợp đặc trưng BERT và đặc trưng từ điển\n        self.feature_combiner = nn.Linear(self.bert_output_dim + self.lexicon_features_dim, 512)\n        \n        # Lớp phân loại\n        self.classifier = nn.Linear(512, num_classes)\n        \n        # Hàm kích hoạt\n        self.relu = nn.ReLU()\n    \n    def forward(self, input_ids, attention_mask, lexicon_features):\n        # Đầu ra từ mô hình BERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        \n        # Kết hợp đặc trưng BERT và đặc trưng từ điển\n        combined_features = torch.cat((pooled_output, lexicon_features), dim=1)\n        combined_features = self.feature_combiner(combined_features)\n        combined_features = self.relu(combined_features)\n        combined_features = self.dropout(combined_features)\n        \n        # Phân loại\n        logits = self.classifier(combined_features)\n        \n        return logits\n\n# Hàm dự đoán cảm xúc cho văn bản mới\ndef predict_emotion(text, model, tokenizer, emotion_dict):\n    # Tiền xử lý văn bản\n    text = preprocess_text(text)\n    \n    # Tokenize văn bản\n    encoding = tokenizer(\n        text,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    # Trích xuất đặc trưng từ từ điển cảm xúc\n    lexicon_features = extract_lexicon_features(text, emotion_dict)\n    \n    # Đưa dữ liệu lên thiết bị\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    lexicon_features = torch.tensor([lexicon_features], dtype=torch.float).to(device)\n    \n    # Dự đoán\n    model.eval()\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask, lexicon_features)\n        _, preds = torch.max(outputs, dim=1)\n    \n    # Ánh xạ số sang nhãn cảm xúc\n    emotion_map = {\n        0: 'Anger',\n        1: 'Disgust',\n        2: 'Fear',\n        3: 'Enjoyment',\n        4: 'Sadness',\n        5: 'Surprise'\n    }\n    \n    # Lấy xác suất cho mỗi cảm xúc\n    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n    probs_dict = {emotion_map[i]: float(probabilities[0][i]) for i in range(6)}\n    \n    return emotion_map[preds.item()], probs_dict\n\n# Hàm tương tác với người dùng\ndef get_user_input():\n    print(\"\\nChọn phương thức nhập dữ liệu:\")\n    print(\"1. Nhập văn bản trực tiếp\")\n    print(\"2. Nhập đường dẫn đến file văn bản\")\n    print(\"3. Thoát\")\n    \n    choice = input(\"Nhập lựa chọn của bạn (1-3): \")\n    \n    if choice == '1':\n        text = input(\"\\nNhập văn bản cần dự đoán cảm xúc: \")\n        return {'type': 'text', 'content': text}\n    elif choice == '2':\n        file_path = input(\"\\nNhập đường dẫn đến file văn bản: \")\n        return {'type': 'file', 'content': file_path}\n    elif choice == '3':\n        return {'type': 'exit'}\n    else:\n        print(\"Lựa chọn không hợp lệ. Vui lòng chọn lại.\")\n        return get_user_input()\n\n# Hàm xử lý dự đoán cho văn bản\ndef process_text(text, model, tokenizer, emotion_dict):\n    emotion, probs = predict_emotion(text, model, tokenizer, emotion_dict)\n    print(f\"\\nVăn bản: {text}\")\n    print(f\"Cảm xúc dự đoán: {emotion}\")\n    print(\"\\nXác suất cho mỗi cảm xúc:\")\n    for emotion, prob in sorted(probs.items(), key=lambda x: x[1], reverse=True):\n        print(f\"{emotion}: {prob:.4f}\")\n\n# Hàm xử lý dự đoán cho file\ndef process_file(file_path, model, tokenizer, emotion_dict):\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            texts = f.readlines()\n        \n        print(f\"\\nĐã đọc {len(texts)} dòng từ file {file_path}\")\n        \n        results = []\n        for i, text in enumerate(texts):\n            text = text.strip()\n            if text:  # Bỏ qua dòng trống\n                emotion, probs = predict_emotion(text, model, tokenizer, emotion_dict)\n                results.append({\n                    'text': text,\n                    'emotion': emotion,\n                    'probabilities': probs\n                })\n                print(f\"Dòng {i+1}: {emotion}\")\n        \n        # Lưu kết quả vào file\n        output_file = file_path.rsplit('.', 1)[0] + '_predictions.csv'\n        df = pd.DataFrame(results)\n        df.to_csv(output_file, index=False)\n        print(f\"\\nĐã lưu kết quả dự đoán vào file {output_file}\")\n    \n    except Exception as e:\n        print(f\"Lỗi khi đọc file: {e}\")\n\n# Hàm chính\ndef main():\n    # Phân tích tham số dòng lệnh\n    parser = argparse.ArgumentParser(description='Dự đoán cảm xúc cho văn bản tiếng Việt')\n    parser.add_argument('--model', type=str, default='/kaggle/working/models/best_model.pt', help='Đường dẫn đến file mô hình đã huấn luyện')\n    args = parser.parse_args([])\n    \n    # Đọc từ điển cảm xúc\n    print(\"Đang đọc từ điển cảm xúc...\")\n    emotion_dict = load_vnemolex()\n    \n    # Tải mô hình và tokenizer\n    print(\"Đang tải mô hình CafeBERT...\")\n    tokenizer = AutoTokenizer.from_pretrained('uitnlp/CafeBERT')\n    bert_model = AutoModel.from_pretrained('uitnlp/CafeBERT')\n    \n    # Tạo mô hình\n    print(\"Đang khởi tạo mô hình...\")\n    model = EmotionClassifier(bert_model)\n    model.to(device)\n    \n    # Tải trọng số mô hình đã huấn luyện\n    print(f\"Đang tải mô hình đã huấn luyện từ {args.model}...\")\n    model.load_state_dict(torch.load(args.model, map_location=device), strict=False)\n    print(\"Mô hình đã được tải thành công với strict=False để bỏ qua các khóa không khớp!\")\n    \n    # Vòng lặp tương tác với người dùng\n    while True:\n        user_input = get_user_input()\n        \n        if user_input['type'] == 'exit':\n            print(\"Tạm biệt!\")\n            break\n        elif user_input['type'] == 'text':\n            process_text(user_input['content'], model, tokenizer, emotion_dict)\n        elif user_input['type'] == 'file':\n            process_file(user_input['content'], model, tokenizer, emotion_dict)\n\n# Chạy chương trình\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T16:58:03.844043Z","iopub.execute_input":"2025-05-31T16:58:03.844265Z","iopub.status.idle":"2025-05-31T17:02:02.923323Z","shell.execute_reply.started":"2025-05-31T16:58:03.844250Z","shell.execute_reply":"2025-05-31T17:02:02.922669Z"}},"outputs":[{"name":"stdout","text":"Đang đọc từ điển cảm xúc...\nĐang tải mô hình CafeBERT...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Đang khởi tạo mô hình...\nĐang tải mô hình đã huấn luyện từ /kaggle/working/models/best_model.pt...\nMô hình đã được tải thành công với strict=False để bỏ qua các khóa không khớp!\n\nChọn phương thức nhập dữ liệu:\n1. Nhập văn bản trực tiếp\n2. Nhập đường dẫn đến file văn bản\n3. Thoát\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập lựa chọn của bạn (1-3):  1\n\nNhập văn bản cần dự đoán cảm xúc:  Khi bạn nghĩ rằng cuộc sống của bạn là hoàn hảo, không còn mục đích lớn lao nào nữa. Nó có nghĩa là cuộc sống đã mất rất nhiều ý nghĩa.\n"},{"name":"stdout","text":"\nVăn bản: Khi bạn nghĩ rằng cuộc sống của bạn là hoàn hảo, không còn mục đích lớn lao nào nữa. Nó có nghĩa là cuộc sống đã mất rất nhiều ý nghĩa.\nCảm xúc dự đoán: Sadness\n\nXác suất cho mỗi cảm xúc:\nSadness: 0.7884\nDisgust: 0.1625\nEnjoyment: 0.0290\nFear: 0.0116\nAnger: 0.0057\nSurprise: 0.0028\n\nChọn phương thức nhập dữ liệu:\n1. Nhập văn bản trực tiếp\n2. Nhập đường dẫn đến file văn bản\n3. Thoát\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập lựa chọn của bạn (1-3):  1\n\nNhập văn bản cần dự đoán cảm xúc:  Đừng bao giờ từ bỏ ước mơ của mình. Hãy tắt báo thức và lăn ra ngủ tiếp\n"},{"name":"stdout","text":"\nVăn bản: Đừng bao giờ từ bỏ ước mơ của mình. Hãy tắt báo thức và lăn ra ngủ tiếp\nCảm xúc dự đoán: Enjoyment\n\nXác suất cho mỗi cảm xúc:\nEnjoyment: 0.4735\nSadness: 0.3993\nDisgust: 0.1011\nFear: 0.0189\nAnger: 0.0045\nSurprise: 0.0028\n\nChọn phương thức nhập dữ liệu:\n1. Nhập văn bản trực tiếp\n2. Nhập đường dẫn đến file văn bản\n3. Thoát\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập lựa chọn của bạn (1-3):  1\n\nNhập văn bản cần dự đoán cảm xúc:  Tui tao không ngờ được đây là trường tui\n"},{"name":"stdout","text":"\nVăn bản: Tui tao không ngờ được đây là trường tui\nCảm xúc dự đoán: Surprise\n\nXác suất cho mỗi cảm xúc:\nSurprise: 0.9824\nEnjoyment: 0.0104\nSadness: 0.0024\nDisgust: 0.0023\nFear: 0.0015\nAnger: 0.0010\n\nChọn phương thức nhập dữ liệu:\n1. Nhập văn bản trực tiếp\n2. Nhập đường dẫn đến file văn bản\n3. Thoát\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Nhập lựa chọn của bạn (1-3):  3\n"},{"name":"stdout","text":"Tạm biệt!\n","output_type":"stream"}],"execution_count":15}]}